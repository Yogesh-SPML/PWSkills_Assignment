{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is the KNN algorithm?"
      ],
      "metadata": {
        "id": "yjB8hMxHE_Vw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNN is an algorithm that is used for classification and regression."
      ],
      "metadata": {
        "id": "XO2OzQKBFIHF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. How do you choose the value of K in KNN?"
      ],
      "metadata": {
        "id": "61Jv9mX0FLtL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The value of K in KNN is usually chosen by cross-validation."
      ],
      "metadata": {
        "id": "WGwIsxldFMsC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. What is the difference between KNN classifier and KNN regressor?"
      ],
      "metadata": {
        "id": "001kytg-FVDv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNN classifier is used for classification problems where the output variable is categorical, while KNN regressor is used for regression problems where the output variable is continuous."
      ],
      "metadata": {
        "id": "nQ0XxmyKFV-e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. How do you measure the performance of KNN?\n"
      ],
      "metadata": {
        "id": "JA99WNwEFd02"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The performance of KNN is typically measured using metrics such as accuracy, precision, recall, and F1 score."
      ],
      "metadata": {
        "id": "APqfrQ_wFepA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. What is the curse of dimensionality in KNN?"
      ],
      "metadata": {
        "id": "nkG5mZw_Fi37"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The curse of dimensionality in KNN refers to the problem where the performance of the algorithm decreases as the number of features or dimensions increases."
      ],
      "metadata": {
        "id": "uTYblyRUFmn7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. How do you handle missing values in KNN?\n"
      ],
      "metadata": {
        "id": "5UJwnoSuF08-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One way to handle missing values in KNN is to use imputation techniques such as mean imputation, median imputation, or KNN imputation to fill in the missing values before applying the algorithm. Another approach is to discard the instances with missing values.\n"
      ],
      "metadata": {
        "id": "mHqtBqh3Fz59"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8. What are the strengths and weaknesses of the KNN algorithm for classification and regression tasks,\n",
        "and how can these be addressed?\n"
      ],
      "metadata": {
        "id": "h9vVepXWF3LA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The strengths of the KNN algorithm for classification and regression tasks are that it is simple to understand and implement, it can work well with nonlinear relationships, and it can handle multiple classes. However, it can be computationally expensive, especially with large datasets, and it can be sensitive to the choice of K and the distance metric used. These weaknesses can be addressed by using techniques such as dimensionality reduction, distance weighting, and cross-validation to optimize the algorithm's performance.\n"
      ],
      "metadata": {
        "id": "Mus_nczNF8Vl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q9. What is the difference between Euclidean distance and Manhattan distance in KNN?\n"
      ],
      "metadata": {
        "id": "4q2qGKDpFnV4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Euclidean distance is the straight-line distance between two points in a Euclidean space, while Manhattan distance is the distance between two points measured along the axes at right angles in a Euclidean space. In other words, Euclidean distance is the shortest distance between two points, while Manhattan distance is the sum of the absolute differences between the coordinates of the two points. In KNN, the choice of distance metric can affect the algorithm's performance, and the choice between Euclidean and Manhattan distance depends on the nature of the data and the problem being solved.\n"
      ],
      "metadata": {
        "id": "2FggUy_jGIu6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z3YnbxfzFSln"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}